{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COM S 579 BERT MODEL\n",
    "Goal for 3rd two weeks: Detect the type of NEs. For example in CoNLL, there are 5 types:  non-NE/O, PERson, ORGanizatin, LOCation, Miscellaneous. The goal for the 3rd two weeks is to predict the type correctly. First obtained the contextual embedding for each token using a BERT-like model. Then train a neural network to predict the type of each token from their BERT-embedding. The neural network is shared by all tokens. There are several strategies. You can do a 9-class classification (B/I- 4 types, and O ) or you can do in two separate NNs, the first stage predict B/I/O while the second predicts the 5 types.   \n",
    "\n",
    "Team group: Mario Mastrandrea, Yuting Yang\n",
    "\n",
    "Python version: Python 3.10.5 64-bit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import CONLL2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/mariomastrandrea/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084c63ec73454a90911395ba1c6c1343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"NER label names in CONLL2003\"\"\"\n",
    "label_names = dataset['train'].features['ner_tags'].feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:      EU    rejects German call to boycott British lamb . \n",
      "NER tag no.: 3     0       7      0    0  0       7       0    0 \n",
      "NER tag:     B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check the correspondence among tokens, NER tags in string, and NER tags in number\"\"\"\n",
    "tokens = dataset['train'][0]['tokens']\n",
    "labels = dataset['train'][0]['ner_tags']\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "line3 = \"\"\n",
    "for token, label in zip(tokens, labels):\n",
    "    full_label = label_names[label]\n",
    "    # print(label, full_label)\n",
    "    max_length = max(len(token), len(full_label))  \n",
    "    line1 += token + \" \" * (max_length - len(token) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "    line3 += str(label) + \" \" * (max_length)\n",
    "print(f'Tokens:      {line1}')\n",
    "\n",
    "print(f'NER tag no.: {line3}')\n",
    "print(f'NER tag:     {line2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create *Tokenizer* object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  str tokens:   [CLS] EU   rejects German call to   boycott British la   ##mb  .   [SEP]\n",
      "  int tokens:   101   7270 22961   1528   1840 1106 21423   1418    2495 12913 119 102  \n",
      "aligned tags:   -100  3    0       7      0    0    0       7       0    0     0   -100 \n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(dataset['train'][0]['tokens'], is_split_into_words=True)\n",
    "#Â print(inputs.tokens())\n",
    "# print(inputs['input_ids'])\n",
    "# print(dataset['train'][0]['ner_tags'])\n",
    "# print(inputs.word_ids())\n",
    "new_labels = align_labels_with_tokens(dataset['train'][0]['ner_tags'], inputs.word_ids())\n",
    "\n",
    "\n",
    "tokens_line = []\n",
    "input_ids_line = []\n",
    "new_labels_line = []\n",
    "\n",
    "for token, input_id, new_label in zip(inputs.tokens(), inputs['input_ids'], new_labels):\n",
    "    token = str(token)\n",
    "    input_id = str(input_id)\n",
    "    new_label = str(new_label)\n",
    "    max_length = max(len(token), len(input_id), len(new_label))\n",
    "\n",
    "    if len(token) == max_length:\n",
    "        tokens_line.append(token)\n",
    "        input_ids_line.append(input_id + (\" \" * (max_length - len(input_id))))\n",
    "        new_labels_line.append(new_label + (\" \" * (max_length - len(new_label))))\n",
    "\n",
    "    elif len(input_id) == max_length:\n",
    "        tokens_line.append(token + (\" \" * (max_length - len(token))))\n",
    "        input_ids_line.append(input_id)\n",
    "        new_labels_line.append(new_label + (\" \" * (max_length - len(new_label))))\n",
    "\n",
    "    elif len(new_label) == max_length:\n",
    "        tokens_line.append(token + (\" \" * (max_length - len(token))))\n",
    "        input_ids_line.append(input_id + (\" \" * (max_length - len(input_id))))\n",
    "        new_labels_line.append(new_label)\n",
    "    \n",
    "print(\"  str tokens:   \" + \" \".join(tokens_line))\n",
    "print(\"  int tokens:   \" + \" \".join(input_ids_line))\n",
    "print(\"aligned tags:   \" + \" \".join(new_labels_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['label'] = [-100, 7, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize CONLL2003 training set and align labels with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id] \n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id] \n",
    "            # for tokens with the same word_id. The tokens correspond to one entity. The first token is B and the rest are Is. However, labels[word_id] only returns the token labeled with \"B\", of which the NER tagging integer is always an odd number. As the word_ids passed to this step represent \"I\" tokens, we need to convert the label the even number, which represents the tokens labeled with \"I\"\n",
    "            \n",
    "            # print(f'before: {label}')\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            # print(f'after: {label}')\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-100, 7, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = dataset['train'][10]['ner_tags']\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenzied_inputs = tokenizer(\n",
    "        examples['tokens'], truncation = True, is_split_into_words = True\n",
    "    )\n",
    "    all_labels = examples['ner_tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenzied_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenzied_inputs['labels'] = new_labels\n",
    "    return tokenzied_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/mariomastrandrea/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-77a1416803abdc9a.arrow\n",
      "Loading cached processed dataset at /Users/mariomastrandrea/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-e4239e5b11dd4f73.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea0417da95e4073bc0a859c640c8e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched = True,\n",
    "    remove_columns = dataset['train'].column_names\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fine-tune the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_dataset['train'][i] for i in range(2)])\n",
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load('seqeval')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=2)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)} # the correspondence between label names and label ids\n",
    "label2id = {n: m for m, n in id2label.items()}\n",
    "id2label\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "     'bert-base-cased',\n",
    "     num_labels = 9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model1 = AutoModelForTokenClassification.from_pretrained(\n",
    "     'bert-base-cased', # whether to distinguish capitalization\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    'bert-finetuned-ner',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # save_strategy = 'epoch',\n",
    "    per_device_train_batch_size= 16,\n",
    "    per_device_eval_batch_size= 16,\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 3,\n",
    "    weight_decay = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = tokenized_dataset['train'],\n",
    "    eval_dataset = tokenized_dataset['validation'],\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2634\n",
      "  Number of trainable parameters = 107726601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34e3c781bef4577977735a7ef703b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-500\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1664, 'learning_rate': 1.604403948367502e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5d0d2f8cd04fc39d2b0a6c6b8d5193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0627116933465004, 'eval_precision': 0.9042239685658153, 'eval_recall': 0.9294850218781555, 'eval_f1': 0.9166804979253111, 'eval_accuracy': 0.9818096191205039, 'eval_runtime': 337.2949, 'eval_samples_per_second': 9.635, 'eval_steps_per_second': 0.605, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-1000\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0737, 'learning_rate': 1.2247532270311316e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-1500\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0445, 'learning_rate': 8.45102505694761e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8af8319bb7c401e8538f51b9dabb93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05602369084954262, 'eval_precision': 0.9278043945151164, 'eval_recall': 0.9451363177381353, 'eval_f1': 0.9363901625677366, 'eval_accuracy': 0.9853711661859069, 'eval_runtime': 366.0124, 'eval_samples_per_second': 8.879, 'eval_steps_per_second': 0.557, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-2000\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0333, 'learning_rate': 4.6545178435839035e-06, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-2500\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0261, 'learning_rate': 8.580106302201975e-07, 'epoch': 2.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-2500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957da81f051c49c591387d8e6aeb1fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05379325523972511, 'eval_precision': 0.9292079207920793, 'eval_recall': 0.9476607202961965, 'eval_f1': 0.9383436093984335, 'eval_accuracy': 0.9859598516512628, 'eval_runtime': 415.2941, 'eval_samples_per_second': 7.826, 'eval_steps_per_second': 0.491, 'epoch': 3.0}\n",
      "{'train_runtime': 18738.9061, 'train_samples_per_second': 2.248, 'train_steps_per_second': 0.141, 'train_loss': 0.06635913273196557, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2634, training_loss=0.06635913273196557, metrics={'train_runtime': 18738.9061, 'train_samples_per_second': 2.248, 'train_steps_per_second': 0.141, 'train_loss': 0.06635913273196557, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "__Fifth Try__\n",
    "model\n",
    "axis = 2 \n",
    "num_train_epochs = 3\n",
    "per_device_train_batch_size = 16\n",
    "per_device_evl_batch_size = 16\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1756\n",
      "  Number of trainable parameters = 108898569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5b3525db1412f9dd0fad459ae592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7376, 'learning_rate': 1.4305239179954442e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4935, 'learning_rate': 8.610478359908885e-06, 'epoch': 0.57}\n",
      "{'loss': 0.4375, 'learning_rate': 2.9157175398633257e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a4412207d54f69a82d2ea25b4ebf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-finetuned-ner/checkpoint-1756\n",
      "Configuration saved in bert-finetuned-ner/checkpoint-1756/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38606491684913635, 'eval_precision': 0.4584942084942085, 'eval_recall': 0.39969707169303265, 'eval_f1': 0.42708146016903437, 'eval_accuracy': 0.8789221169129334, 'eval_runtime': 132.737, 'eval_samples_per_second': 24.485, 'eval_steps_per_second': 3.066, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner/checkpoint-1756/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner/checkpoint-1756/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner/checkpoint-1756/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3100.5381, 'train_samples_per_second': 4.529, 'train_steps_per_second': 0.566, 'train_loss': 0.5357341375329229, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1756, training_loss=0.5357341375329229, metrics={'train_runtime': 3100.5381, 'train_samples_per_second': 4.529, 'train_steps_per_second': 0.566, 'train_loss': 0.5357341375329229, 'epoch': 1.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "__Fourth Try__\n",
    "model\n",
    "axis = -1 \n",
    "num_train_epochs = 1\n",
    "__SUCCESSFUL OUTPUT BUT LOW PERFORMANCE__\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5268\n",
      "  Number of trainable parameters = 107726601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00effe0284c64b07970d33c4ddbd056e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0221, 'learning_rate': 4.768413059984815e-06, 'epoch': 0.28}\n",
      "{'loss': 0.0217, 'learning_rate': 2.8701594533029615e-06, 'epoch': 0.57}\n",
      "{'loss': 0.0216, 'learning_rate': 9.719058466211087e-07, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1528\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1529\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1530\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1531\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1532\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1867\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1867\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1869\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   1870\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1871\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2115\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2109\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2110\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2111\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2112\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2113\u001b[0m             )\n\u001b[1;32m   2114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2115\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2811\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2808\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2810\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2811\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2812\u001b[0m     eval_dataloader,\n\u001b[1;32m   2813\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2814\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2815\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2816\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2817\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2818\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2819\u001b[0m )\n\u001b[1;32m   2821\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2822\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2823\u001b[0m     speed_metrics(\n\u001b[1;32m   2824\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2828\u001b[0m     )\n\u001b[1;32m   2829\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3093\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[1;32m   3094\u001b[0m         )\n\u001b[1;32m   3095\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3096\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[1;32m   3097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3098\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_predictions)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "__Third Try__\n",
    "model1\n",
    "axis = -1 \n",
    "excluded 'fi' and 'accuracy' in the evaluation metrics\n",
    "num_train_epochs = 3\n",
    "__ERROR__\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5268\n",
      "  Number of trainable parameters = 107726601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b499e9e0fd462e8bc76a76398571b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0441, 'learning_rate': 1.143507972665148e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0438, 'learning_rate': 9.53682611996963e-06, 'epoch': 0.57}\n",
      "{'loss': 0.0384, 'learning_rate': 7.638572513287777e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1528\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1529\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1530\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1531\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1532\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1867\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1867\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1869\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   1870\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1871\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2115\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2109\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2110\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2111\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2112\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2113\u001b[0m             )\n\u001b[1;32m   2114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2115\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2811\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2808\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2810\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2811\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2812\u001b[0m     eval_dataloader,\n\u001b[1;32m   2813\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2814\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2815\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2816\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2817\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2818\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2819\u001b[0m )\n\u001b[1;32m   2821\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2822\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2823\u001b[0m     speed_metrics(\n\u001b[1;32m   2824\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2828\u001b[0m     )\n\u001b[1;32m   2829\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3093\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[1;32m   3094\u001b[0m         )\n\u001b[1;32m   3095\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3096\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[1;32m   3097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3098\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_predictions)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "__Second Try__\n",
    "model1\n",
    "axis = -1 \n",
    "num_train_epochs = 3\n",
    "__ERROR__\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5268\n",
      "  Number of trainable parameters = 107726601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02178b77fc374e01b1233007a09cd9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2574, 'learning_rate': 1.810174639331815e-05, 'epoch': 0.28}\n",
      "{'loss': 0.098, 'learning_rate': 1.6203492786636296e-05, 'epoch': 0.57}\n",
      "{'loss': 0.089, 'learning_rate': 1.4305239179954442e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce303b7be4444b69d2437e11251693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1528\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1529\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1530\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1531\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1532\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1867\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1867\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1869\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   1870\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1871\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2115\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2109\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2110\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2111\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2112\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2113\u001b[0m             )\n\u001b[1;32m   2114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2115\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2811\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2808\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2810\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2811\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2812\u001b[0m     eval_dataloader,\n\u001b[1;32m   2813\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2814\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2815\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2816\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2817\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2818\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2819\u001b[0m )\n\u001b[1;32m   2821\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2822\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2823\u001b[0m     speed_metrics(\n\u001b[1;32m   2824\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2828\u001b[0m     )\n\u001b[1;32m   2829\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3093\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[1;32m   3094\u001b[0m         )\n\u001b[1;32m   3095\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3096\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[1;32m   3097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3098\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_predictions)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/yangyuting/Library/Mobile Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM S 579X NLP/Project1/WikiNER/COM S579_BERTModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[label_names[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m label \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [[label_names[p] \u001b[39mfor\u001b[39;00m (p, i) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(prediction, label) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mfor\u001b[39;00m (prediction, label) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (predictions, labels)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m true_predictions, reference \u001b[39m=\u001b[39m true_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: all_metrics[\u001b[39m'\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyuting/Library/Mobile%20Documents/com~apple~CloudDocs/01PhD/02ISU/04Classes/2022Fall/COM%20S%20579X%20NLP/Project1/WikiNER/COM%20S579_BERTModel.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "__First Try__\n",
    "model1\n",
    "axis = 1\n",
    "num_train_epochs = 3\n",
    "__ERROR__\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
